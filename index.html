<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>SIGHAN 2024 Shared Task</title>

    
    <!-- 匯入bootstrap -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  
    <!-- 匯入jQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <!-- Optional theme -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


    <!-- 插入方程式 -->
    <script async src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link rel="stylesheet" href="main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

<!-- ============================================================================ -->


    <div>
        <nav class="nav navbar-default navbar-fixed-top topflex" id="topdiv">

            <div class="navbar-header" id="navheader">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#collapsingNavbarMd">
                    <span class="sr-only"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

            <div class="collapse navbar-collapse navbar-collapse-center" id="collapsingNavbarMd">
                <ul class="nav navbar-nav navbar-center" >

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#intro">Introduction</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#task">Task Description</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#registration">Data Sets</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#key_note">Evaluation</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#tutor">Task Paper</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#ranking">Official Ranking</a></li>
                    
                    <li class="single"><a href="javascript:;" class="navItems" navTo="#special">Important Dates</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#ref">References</a></li>

                    

                </ul>
            </div>
        </nav>
    </div>
   

    <!-- ============================================================================ -->

    <div class="welcome">
        <div class="wrap">
            <div class="item text">
                <h1>SIGHAN 2024 Shared Task<br>
                Chinese Dimensional Aspect-Based Sentiment Analysis (dimABSA)</h1>
                <div class="session">
                    <h2>
                        Organizers
                    </h2>
                    <div class="people">
                        <div class="author">
                            <img src="image/Organizers/lhlee.png">
                            <p>
                                <strong>Lung-Hao Lee</strong><br>
                                National Yang Ming <br>
                                Chiao Tung University<br>
                                <a href="mailto:lhlee@nycu.edu.tw" title="lhlee@nycu.edu.tw">lhlee@nycu.edu.tw </a>
                            </p>
                        </div>
        
                        <div class="author">
                            <img src="image/Organizers/lcyu.jpg">
                            <p>
                                <strong>Liang-Chih Yu</strong><br>
                                Yuan Ze University<br>
                                <a href="mailto:lcyu@saturn.yzu.edu.tw" title="lcyu@saturn.yzu.edu.tw">lcyu@saturn.yzu.edu.tw</a>
                            </p>
                        </div>
        
                        <div class="author">
                            <img src="image/Organizers/wsg.png">
                            <p>
                                <strong>Suge Wang</strong><br>
                                Shanxi University<br>
                                <a href="mailto:wsg@sxu.edu.cn" title="wsg@sxu.edu.cn">wsg@sxu.edu.cn</a>
                            </p>
                        </div>
                        <div class="author">
                            <img src="image/Organizers/cliaoj.png">
                            <p>
                                <strong>Jian Liao</strong><br>
                                Shanxi University<br>
                                <a href="mailto:liaoj@sxu.edu.cn" title="liaoj@sxu.edu.cn">liaoj@sxu.edu.cn</a>
                            </p>
                        </div>
                        
                    </div>

                </div>
            </div>
        </div>    
    </div>

    <!-- ============================================================================ -->

    <div class="introduction" id="intro">

        
        <div class="contact_div_before">
            <div class="contact_div">
                
                <div class="contact_p">
                    <h1>Contact</h1>
                    <p>Join our <strong>WeChat Group</strong> (Chinese) for updates and discussion on the shared task!</p>
                    <p>If you have any questions, please email (English/Chinese) us.</p>
                
                </div>
                <div class="wechat">
                    <!-- <p>If you have any questions, </p> -->
                    <img src ="image/wechat.jpg">
                </div>
            </div>
            
        </div>

        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Registration and Submission</h1>
                <p>CodaBench page: <a href="https://www.codabench.org/competitions/2137/" target="_blank">https://www.codabench.org/competitions/2137/</a></p>
            </div>
        </div>
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Introduction</h1>
                <p>Aspect-Based Sentiment Analysis (ABSA) (Pontiki et al., 2014; 2015; 2016) is a critical NLP research topic that aims to identify the aspects of a given entity and analyzing the sentiment polarity associated with each aspect. In recent years, numerous research effects have been made on ABSA, which can be categorized into different tasks based on the number of sentimental elements to be extracted. For example, Aspect Sentiment Triplet Extraction (ASTE) (Yu et al., 2023; Chen et al., 2021; Mao et al., 2021; Peng et al., 2020; Wu et al., 2020; Xu et al., 2020; Zhang et al., 2020) task extracts three elements in a triplet, including aspect/target term, opinion term and sentiment polarity (e.g., positive, neutral, and negative). Furthermore, Aspect Sentiment Quadruple Prediction (ASQP) (Cai et al., 2021; Gao et al., 2022; Mao et al., 2022; Peper & Wang, 2022; Zhang et al., 2021; Zhou et al., 2023) task extracts the same three elements plus an additional aspect category to construct a quadruple. However, compared to representing affective states as several discrete classes (i.e., polarity), the dimensional approach that represents affective states as continuous numerical values (called intensity) in multiple dimensions such as valence-arousal (VA) space (Russel, 1980), providing more fine-grained emotional information (Lee et al., 2022). </p>
                <p>Therefore, we organize a Chinese dimensional ABSA shared task (dimABSA) in the SIGHAN 2024 workshop, providing fine-grained sentiment intensity prediction for each extracted aspect of a restaurant review. The four sentiment elements are defined as follows:</p>
            </div>
        </div>
        <div class="table_div_mid">
            <ul style="text-align:left">
                <li><strong>Aspect Term (shorted as A): </strong>This denotes an entity indicating the opinion target. If the aspect is omitted without being mentioned clearly, we use “NULL” to represent the term.</li>
                <li><strong>Aspect Category (C): </strong>This represents a predefined category for the explicit aspect of the restaurant domain. We use the same categories defined in the SemEval-2016 Restaurant dataset (Pontiki et al., 2016). There are a total of twelve categories; each can be split into an entity and attribute using the symbol “#.” We describe them as follows: “餐廳#概括” (餐厅#概括, restaurant#general), “餐廳#價格”(餐厅#价格, restaurant#prices), “餐廳#雜項” (餐厅#杂项, restaurant#miscellaneous),“食物#價格” (食物#价格, food#prices), “食物#品質” (食物#品质, food#quality), “食物#份量與款式”(食物#份量与款式, food#style&options), “飲料#價格” (饮料#价格, drinks#prices), “飲料#品質”(饮料#品质, drinks#quality), “飲料#份量與款式”(饮料#份量与款式, drinks#style&options), “氛圍#概括”(氛围#概括, ambience#general), “服務#概括” (服务#概括, services#general) and “地點#概括” (地点#概括, location#general). </li>
                <li><strong>Opinion Term (O): </strong>This describes the sentiment words or phrases towards the aspects.</li>
                <li><strong>Sentiment Intensity (I): </strong>This reflects respective sentiments using continuous real-valued scores in the valence-arousal dimensions. The valence represents the degree of pleasant and unpleasant (i.e., positive and negative) feelings, while the arousal represents the degree of excitement and calm. Both the valence and arousal dimensions use a nine-degree scale. Value 1 on the valence and arousal dimensions denotes extremely high-negative and low-arousal sentiment, respectively. In contrast, 9 denotes extremely high-positive and high-arousal sentiment, and 5 denotes a neutral and medium-arousal sentiment. Valence-arousal values are separated by a hashtag (symbol “#”) for a mark.</li>
            </ul>
        </div>
    </div>
    
    <!-- ============================================================================ -->

    <div class='task' id='task'>
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Task Description</h1>
                <p>This task aims to evaluate the capability of an automatic system for Chinese dimensional ABSA. This task can be further divided into three subtasks described as follows.
                </p>
                <h2>Subtask 1: Intensity Prediction</h2>
                <p>The first subtask focuses on predicting sentiment intensities in the valence-arousal dimensions. Given a sentence and a specific aspect, the system should predict the valence-arousal ratings. The input format consists of ID, sentence, and aspect. The output format consists of the ID and valence-arousal predicted values that are separated with a 'space'. The intensity prediction is two real-valued scores rounded to two decimal places and separated by a hashtag, each denotes the valence and arousal rating, respectively.</p>
                <div class="part">
                    <h3>Example 1</h3>
                    <p>(Traditional Chinese version)</p>
                    <p>Input: E0001:S001, 檸檬醬也不會太油，塔皮對我而言稍軟。, 檸檬醬#塔皮</p>
                    <p>Output: E0001:S001 (檸檬醬,5.67#5.5)(塔皮,4.83#5.0)</p>
                    <p></p>
                    <p>(Simplified Chinese version)</p>
                    <p>Input: E0001:S001, 柠檬酱也不会太油，塔皮对我而言稍软。 柠檬酱#塔皮</p>
                    <p>Output: E0001:S001 (柠檬酱,5.67#5.5)(塔皮,4.83#5.0)</p>
                    <p></p>
                </div>
                
                <h2>Subtask 2: Triplet Extraction</h2>
                <p>The second subtask aims to extract sentiment triplets composed of three elements. Given a sentence only, the system should extract all sentiment triplets (aspect, opinion, intensity). The output format consists of the ID and sentiment triplet that are separated with a 'space'.</p>
                <div class="part">
                    <h3>Example 2</h3>
                    <p>(Traditional Chinese version)</p>
                    <p>Input: E0002:S002, 不僅餐點美味上菜速度也是飛快耶！！</p>
                    <p>Output: E0002:S002 (餐點, 美味, 6.63#4.63) (上菜速度, 飛快, 7.25#6.00)</p>
                    <p></p>
                    <p>(Simplified Chinese version)</p>
                    <p>Input: E0002:S002, 不仅餐点美味上菜速度也是飞快耶!!</p>
                    <p>Output: E0002:S002 (餐点, 美味, 6.63#4.63) (上菜速度, 飞快, 7.25#6.00)</p>
                    <p></p>
                </div>
                
                <h2>Subtask 3: Quadruple Extraction</h2>
                <p>The third subtask aims to extract sentiment quadruples composed of four elements. Given a sentence only, the system should extract all sentiment quadruples (aspect, category, opinion, intensity). The output format consists of the ID and sentiment quadruple that are separated with a 'space'.</p>
                <div class="part">
                    <h3>Example 3</h3>
                    <p>(Traditional Chinese version)</p>
                    <p>Input: E0003:S003, 這碗拉麵超級無敵霹靂難吃</p>
                    <p>Output: E0003:S003 (拉麵, 食物#品質, 超級無敵霹靂難吃, 2.00#7.88)</p>
                    <p></p>
                    <p>(Simplified Chinese version)</p>
                    <p>Input: E0003:S003, 这碗拉面超级无敌霹雳难吃</p>
                    <p>Output: E0003:S003 (拉面, 食物#品质, 超级无敌霹雳难吃, 2.00#7.88)</p>
                </div>
            </div>  
        </div>
    </div>


    <!-- ============================================================================ -->

    <div class="registration" id="registration">
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Data Sets</h1>
                <p>We first crawled reviews from a popular online social media platform. Then, we removed all HTML tags and multimedia material and split the remaining texts into several sentences. Finally, we randomly selected partial sentences to retain content diversity for manual annotation.</p>
                <p>The annotation process is conducted in two phases. We first annotate the aspect/category/opinion elements and then V#A element. In the first phase, three graduate students majoring in computer science and linguistics will annotate the sentences for aspect/category/opinion. One task organizer will lead a discussion to clarify annotation differences and seek consensus among the annotators. A majority vote mechanism is finally used to resolve any disagreements among the annotators. In the second phase, each sentence along with the annotated aspect/category/opinion will be presented to five annotators majoring in computer science and linguistics for V#A rating. Similarly, one task organizers will also lead a group discussion during annotation. Once the annotation process is finished, a cleanup procedure is performed to remove outlier values which do not fall within 1.5 standard deviations (SD) of the mean. These outliers are then excluded from calculating the average V#A for each instance.</p>
                <div class="part">
                    <h3 style="color: red;">Notes</h3>
                    <p>1.&nbsp;&nbsp;The policy of this shared task is an open test. Participating systems can use other publicly available data for this shared task, but other data should be specified in the final system description paper.</p>
                    <br>
                    <p>2.&nbsp;&nbsp;We will provide two versions of the training set and two test sets. The only difference is the usage of Chinese characters, either in Traditional Chinese or Simplified Chinese. The participating teams can choose their preferred version for the task evaluation. The submitted results will be evaluated with the corresponding version of the gold standard and ranked together as the official results. </p>
                </div>
                <h2>Chinese EmoBank</h2>
                <p><a href="http://nlp.innobic.yzu.edu.tw/resources/ChineseEmoBank.html">http://nlp.innobic.yzu.edu.tw/resources/ChineseEmoBank.html</a></p>
                <br>
                <p>The Chinese EmoBank (Lee et al., 2022) is a dimensional sentiment resource annotated with real-valued scores for both valence and arousal dimensions. The valence represents the degree of positive and negative sentiment, and arousal represents the degree of calm and excitement. Both dimensions range from 1 (highly negative or calm) to 9 (highly positive or excited). The Chinese EmoBank features various levels of text granularity including two lexicons called Chinese valence-arousal words (CVAW, 5,512 single words) and Chinese valence-arousal phrases (CVAP, 2,998 multi-word phrases) and two corpora called Chinese valence-arousal sentences (CVAS, 2,582 single sentences) and Chinese valence-arousal texts (CVAT, 2,969 multi-sentence texts).</p>
                <br>
                <h2>Training set</h2>
                <p>We will provide data sets consisting of at least 3000 annotated sentences for model training and development. Below are samples in a JSON format that can be used for all three subtasks. </p>
                <div class="table_div_mid">
                    <table id='paper-table-1'>
                        <tr>
                            <th>
                                <img src="./image/example.png" alt="nope" style="float: left; max-width: 700px; max-height: 1000px;">
                            </th>
                        </tr>
                    </table>
                </div>
                <h2>Test Set</h2>
                <p>Two mutually exclusive sets are prepared for the corresponding subtasks, respectively; each includes at least 1,000 sentences that will be provided for system performance evaluation. One is provided for Subtask 1, and the other is used for Subtasks 2 & 3.</p>
            </div>  
        </div>
    </div>
    
    <!-- ============================================================================ -->

    <div class="keynote" id="key_note">
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Evaluation</h1>
                <h2>Subtask 1: Mean Absolute Error & Pearson Correlation Coefficient</h2>
                <p>The sentiment intensity prediction performance is evaluated by examining the difference between machine-predicted ratings and human-annotated ratings using two metrics: Mean Absolute Error (MAE) and Pearson Correlation Coefficient (PCC), defined as the following Equations.</p>
                <p><span>$$ MAE = \frac{1}{n} \sum_{i=1}^{n}|a_{i}-p_{i}| $$</span></p>
                <p><span>$$ PCC = \frac{1}{n-1} \sum_{i=1}^{n}(\frac{a_{i}-\mu_{A}}{\sigma_{A}})(\frac{p_{i}-\mu_{P}}{\sigma_{P}}) $$</span></p>
                <p>where \( a_{i}\in{A} \)  and \( p_{i}\in{P} \)  respectively denote the i-th actual value and predicted value, n is the number of test samples, \( \mu_{A} \)  and \( \sigma_{P} \) respectively represent the mean value and the standard deviation of A, while \( \mu_{A} \) and \( \sigma_{P} \) respectively represent the mean value and the standard deviation of P. </p>
                <p>Each metric for the valence and arousal dimensions is calculated and ranked independently. The actual and predicted real values should range from 1 to 9, so MAE measures the error rate in a range where the lowest value is 0 and the highest value is 8. A lower MAE indicates more accurate prediction performance. The PCC is a value between −1 and 1 that measures the linear correlation between the actual and predicted values. A lower MAE and a higher PCC indicate more accurate prediction performance.</p>
                <br></br>
                <h2>Subtasks 2 & 3: Precision, Recall & F1-score</h2>
                <p>First, the valence and arousal values are rounded to an integer. Next, a triplet/quadruple is regarded as correct if and only if the three/four elements and their combination match those in the gold triplet/quadruple. On this basis, we calculate the Precision, Recall, and F1-score as the evaluation metrics, defined as the following equations. </p>
                <p><span>$$ Precision = \frac{TP}{TP+FP} $$</span></p>
                <p><span>$$ Recall = \frac{TP}{TP+FN}  $$</span></p>
                <p><span>$$ F1 = \frac{2*Precision*Recall}{Precision+Recall}  $$</span></p>
                <p>where TP, FP, and FN denote true positives, false positives, and false negatives, respectively. Precision is defined as the percentage of triplets/quadruples extracted by the system that are correct. Recall is the percentage of triplets/quadruples present in the test set found by the system. The F1-score is the harmonic mean of precision and recall. All metrics range from 0 to 1. A higher Precision, Recall, and F1 score indicate more accurate performance. A system’s overall ranking is based on the F1 score. The higher the F1 score, the better the system performance.</p>
                <p>Each metric for the valence and arousal dimensions is calculated and ranked either independently or in combination. Precision is defined as the percentage of triplets/quadruples extracted by the system that are correct. Recall is the percentage of triplets/quadruples present in the test set found by the system. The F1-score is the harmonic mean of precision and recall. All metrics range from 0 to 1. A higher Precision, Recall, and F1 score indicate more accurate performance.</p>
            </div>  
        </div>
   
    </div>

    <!-- ============================================================================ -->

    <div class='Tutorials' id='tutor'>
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Task Paper</h1>
                <p>If you have built a successful system and completed a submission to the <a href="#ranking">leaderboard</a>, we gladly invite you to submit a shared task paper to the SIGHAN 2024 workshop. If you would like to publish a paper, please carefully follow these instructions:</p>
                <div class="part">
                    <p>1.&nbsp;&nbsp;Write your paper using the <a href= https://github.com/acl-org/acl-style-files target="_blank">ACL 2024 template</a>.</p>
                    <br>
                    <p>2.&nbsp;&nbsp;Papers must be written in English.</p>
                    <br>
                    <p>3.&nbsp;&nbsp;Paper titles should adopt the format: <strong>“TEAM_NAME at SIGHAN-2024 dimABSA Task:”</strong> followed by a descriptive title of the proposed approach.</p>
                    <br>
                    <p>4.&nbsp;&nbsp;Submissions are not anonymous for review, so author names and affiliations could be included in the paper.</p>
                    <br>
                    <p>5.&nbsp;&nbsp;The page limitation is four pages (excluding references) for a single subtask; and the length limit is eight pages (excluding references) for multiple subtasks.</p>
                    <br>
                    <p>6.&nbsp;&nbsp;Please cite the following overview paper (just as we will cite your task paper).</p>
                    <p>Lung-Hao Lee, Liang-Chih Yu, Suge Wang, and Jian Liao. 2024. Overview of the SIGHAN 2024 shared task for Chinese dimensional aspect-based sentiment analysis. In <em>Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing</em>. Association for Computational Linguistics.</p>
                    <br>
                    <p>7.&nbsp;&nbsp;Submission Deadline: 17th June, 2024 (anywhere on Earth)</p>
                    <br>
                    <p>8.&nbsp;&nbsp;Submission Site: <a href= https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/SIGHAN-10 target="_blank">OpenReview</a></p>
                    <br>
                    <p>9.&nbsp;&nbsp;<a href= https://docs.google.com/forms/d/e/1FAIpQLSeaJrvX1i3OO5z6-foEZB347jzNOIl30DoQKWjActQuGwZqNg/viewform target="_blank">Reviewer Nomination</a>: Similar to other shared tasks (e.g. SemEval), we ask at least one author per paper also acts as a reviewer. Please nominate the reviewer by the submssion deadline. If you do not nominate a reviewer, the first author or corresponding author will be automatically selected.</p>
                    <br>
                    <p>10.&nbsp;&nbsp;Each accepted task paper will be included in the SIGHAN-2024 proceedings. At least one author must register to present their developed system at the SIGHAN-2024 Workshop (16th August, collocated with ACL 2024, in Bangkok, Thailand).</p>
                </div>
                <p>The evaluation committee will select the Best Evaluation Paper Award and recommend two evaluation papers for publication in the <a href=https://www.mdpi.com/journal/electronics/special_issues/Affective_Computing target="_blank">Special Issue on New Advances in Affective Computing， Electronics (IF 2.9)</a>.</p>
            </div>  
        </div>
    </div>

<!-- ============================================================================ -->
    <div class="introduction" id="ranking">
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Official Ranking</h1>
                
                <p>Notes: Each metric in individual subtask is ranked independently. (*) means the rank for each metric. A system’s overall ranking is computed based on the cumulative rank. The lower the cumulative rank, the better the system performance.</p>
                <br>  
                <style type="text/css">
            .tg  {border-collapse:collapse;border-spacing:0;}
            .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
              overflow:hidden;padding:10px 5px;word-break:normal;}
            .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
              font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
            .tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
            </style>
            <table class="tg"><thead>
              <tr>
                <th class="tg-c3ow" colspan="7">Subtask 1: Intensity Prediction</th>
              </tr></thead>
            <tbody>
              <tr>
                <td class="tg-c3ow" rowspan="2">Team</td>
                <td class="tg-c3ow" rowspan="2">Sub#</td>
                <td class="tg-c3ow" colspan="4">Evaluation Metrics</td>
                <td class="tg-c3ow" rowspan="2">Overall Rank</td>
              </tr>
              <tr>
                <td class="tg-c3ow">V-MAE</td>
                <td class="tg-c3ow">V-PCC</td>
                <td class="tg-c3ow">A-MAE</td>
                <td class="tg-c3ow">A-PCC</td>
              </tr>
              <tr>
                <td class="tg-c3ow">HITSZ-HLT</td>
                <td class="tg-c3ow">63885</td>
                <td class="tg-c3ow">0.279 (1)</td>
                <td class="tg-c3ow">0.933 (1)</td>
                <td class="tg-c3ow">0.309 (1)</td>
                <td class="tg-c3ow">0.777 (1)</td>
                <td class="tg-c3ow">1</td>
              </tr>
              <tr>
                <td class="tg-c3ow">CCIIPLab</td>
                <td class="tg-c3ow">63706</td>
                <td class="tg-c3ow">0.294 (2)</td>
                <td class="tg-c3ow">0.916 (3)</td>
                <td class="tg-c3ow">0.309 (1)</td>
                <td class="tg-c3ow">0.766 (3)</td>
                <td class="tg-c3ow">2</td>
              </tr>
              <tr>
                <td class="tg-c3ow">YUN-HPCC</td>
                <td class="tg-c3ow">63756</td>
                <td class="tg-c3ow">0.294 (2)</td>
                <td class="tg-c3ow">0.917 (2)</td>
                <td class="tg-c3ow">0.318 (3)</td>
                <td class="tg-c3ow">0.771 (2)</td>
                <td class="tg-c3ow">2</td>
              </tr>
              <tr>
                <td class="tg-c3ow">DS-Group</td>
                <td class="tg-c3ow">62014</td>
                <td class="tg-c3ow">0.460 (4)</td>
                <td class="tg-c3ow">0.858 (5)</td>
                <td class="tg-c3ow">0.501 (4)</td>
                <td class="tg-c3ow">0.490 (4)</td>
                <td class="tg-c3ow">4</td>
              </tr>
              <tr>
                <td class="tg-c3ow">yangnan</td>
                <td class="tg-c3ow">61884</td>
                <td class="tg-c3ow">1.032 (5)</td>
                <td class="tg-c3ow">0.877 (4)</td>
                <td class="tg-c3ow">1.095 (5)</td>
                <td class="tg-c3ow">0.097 (5)</td>
                <td class="tg-c3ow">5</td>
              </tr>
            </tbody></table>

            <br>

            <style type="text/css">
            .tg  {border-collapse:collapse;border-spacing:0;}
            .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
              overflow:hidden;padding:10px 5px;word-break:normal;}
            .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
              font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
            .tg .tg-baqh{text-align:center;vertical-align:top}
            .tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
                table {
            margin: auto;
            border-collapse: collapse;
            width: 80%; /* 根据需要调整宽度 */
        }
            </style>
            <table class="tg"><thead>
              <tr>
                <th class="tg-c3ow" colspan="6">Subtask 2: Triplet Extraction</th>
              </tr></thead>
            <tbody>
              <tr>
                <td class="tg-c3ow" rowspan="2">Team</td>
                <td class="tg-c3ow" rowspan="2">Sub#</td>
                <td class="tg-c3ow" colspan="3">Evaluation Metrics</td>
                <td class="tg-c3ow" rowspan="2">Overall Rank</td>
              </tr>
              <tr>
                <td class="tg-c3ow">V-Tri-F1</td>
                <td class="tg-c3ow">A-Tri-F1</td>
                <td class="tg-c3ow">VA-Tri-F1</td>
              </tr>
              <tr>
                <td class="tg-c3ow">HITSZ-HLT</td>
                <td class="tg-c3ow">63885</td>
                <td class="tg-c3ow">0.589 (1)</td>
                <td class="tg-c3ow">0.545 (1)</td>
                <td class="tg-c3ow">0.433 (1)</td>
                <td class="tg-c3ow">1</td>
              </tr>
              <tr>
                <td class="tg-c3ow">CCIIPLab</td>
                <td class="tg-c3ow">63824</td>
                <td class="tg-c3ow">0.573 (2)</td>
                <td class="tg-c3ow">0.522 (2)</td>
                <td class="tg-c3ow">0.403 (2)</td>
                <td class="tg-c3ow">2</td>
              </tr>
              <tr>
                <td class="tg-c3ow">LUCKY-NLP</td>
                <td class="tg-c3ow">63737</td>
                <td class="tg-c3ow">0.542 (3)</td>
                <td class="tg-c3ow">0.507 (3)</td>
                <td class="tg-c3ow">0.389 (3)</td>
                <td class="tg-c3ow">3</td>
              </tr>
              <tr>
                <td class="tg-c3ow">bitnlp</td>
                <td class="tg-c3ow">63766</td>
                <td class="tg-c3ow">0.490 (4)</td>
                <td class="tg-c3ow">0.450 (4)</td>
                <td class="tg-c3ow">0.342 (4)</td>
                <td class="tg-c3ow">4</td>
              </tr>
              <tr>
                <td class="tg-c3ow">SUDA-NLP</td>
                <td class="tg-c3ow">63827</td>
                <td class="tg-c3ow">0.475 (5)</td>
                <td class="tg-c3ow">0.448 (5)</td>
                <td class="tg-c3ow">0.326 (5)</td>
                <td class="tg-c3ow">5</td>
              </tr>
              <tr>
                <td class="tg-baqh">TMAK-Plus</td>
                <td class="tg-baqh">63972</td>
                <td class="tg-baqh">0.269 (6)</td>
                <td class="tg-baqh">0.307 (6)</td>
                <td class="tg-baqh">0.157 (6)</td>
                <td class="tg-baqh">6</td>
              </tr>
            </tbody></table>
            
            <br>

            <style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg"><thead>
  <tr>
    <th class="tg-c3ow" colspan="6">Subtask 3: Quadruple Extraction</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-c3ow" rowspan="2">Team</td>
    <td class="tg-c3ow" rowspan="2">Sub#</td>
    <td class="tg-c3ow" colspan="3">Evaluation Metrics</td>
    <td class="tg-c3ow" rowspan="2">Overall Rank</td>
  </tr>
  <tr>
    <td class="tg-c3ow">V-Quad-F1</td>
    <td class="tg-c3ow">A-Quad-F1</td>
    <td class="tg-c3ow">VA-Quad-F1</td>
  </tr>
  <tr>
    <td class="tg-c3ow">HITSZ-HLT</td>
    <td class="tg-c3ow">63885</td>
    <td class="tg-c3ow">0.567(1)</td>
    <td class="tg-c3ow">0.526 (1)</td>
    <td class="tg-c3ow">0.417 (1)</td>
    <td class="tg-c3ow">1</td>
  </tr>
  <tr>
    <td class="tg-c3ow">CCIIPLab</td>
    <td class="tg-c3ow">63832</td>
    <td class="tg-c3ow">0.555 (2)</td>
    <td class="tg-c3ow">0.507 (2)</td>
    <td class="tg-c3ow">0.389 (2)</td>
    <td class="tg-c3ow">2</td>
  </tr>
  <tr>
    <td class="tg-c3ow">LUCKY-NLP</td>
    <td class="tg-c3ow">61868</td>
    <td class="tg-c3ow">0.522 (3)</td>
    <td class="tg-c3ow">0.489 (3)</td>
    <td class="tg-c3ow">0.376 (3)</td>
    <td class="tg-c3ow">3</td>
  </tr>
  <tr>
    <td class="tg-c3ow">SUDA-NLP</td>
    <td class="tg-c3ow">63622</td>
    <td class="tg-c3ow">0.487 (4)</td>
    <td class="tg-c3ow">0.444 (4)</td>
    <td class="tg-c3ow">0.336 (4)</td>
    <td class="tg-c3ow">4</td>
  </tr>
  <tr>
    <td class="tg-c3ow">JN-NLP</td>
    <td class="tg-c3ow">63572</td>
    <td class="tg-c3ow">0.482 (5)</td>
    <td class="tg-c3ow">0.439 (5)</td>
    <td class="tg-c3ow">0.331 (5)</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-baqh">bitnlp</td>
    <td class="tg-baqh">63766</td>
    <td class="tg-baqh">0.470 (6)</td>
    <td class="tg-baqh">0.434 (7)</td>
    <td class="tg-baqh">0.329 (6)</td>
    <td class="tg-baqh">6</td>
  </tr>
  <tr>
    <td class="tg-baqh">USTC-IAT</td>
    <td class="tg-baqh">63907</td>
    <td class="tg-baqh">0.438 (7)</td>
    <td class="tg-baqh">0.437 (6)</td>
    <td class="tg-baqh">0.312 (7)</td>
    <td class="tg-baqh">7</td>
  </tr>
</tbody></table>
            </div>
        </div>
    </div>
    
    <!-- ============================================================================ -->

    <div class="special_session" id='special'>
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <h1>Important Dates</h1>
                <div class="part">
                    <!-- <h2>Important Dates</h2> -->
                    <!-- <h2>V.&emsp;Important Dates</h2> -->
                        <!-- <p>Registration:
                            <a href="https://docs.google.com/forms/d/e/1FAIpQLSe74D0A_sWAOKH_xtz9_uF7ws9G-cdF2gYiEm5YwONQOcctrA/viewform?vc=0&c=0&w=1&flr=0" target="_blank" title="uninstructed">
                                Click here
                            </a>
                        </p> -->
                    
                    <div class="list">
                        <ul>
                            <li>Release of training data: <strong>1st March, 2024</strong></li>
                            <li>Release of test data: <strong>20th May, 2024</strong></li>
                            <li>Testing results submission due: <strong>25th May, 2024 (08:00 GMT+8)</strong></li>
                            <li>System description paper due: <strong>17th June, 2024 (anywhere on Earth)</strong></li>
                            <li>Notification of Acceptance: <strong>1st July, 2024</strong></li>
                            <li>Camera-ready deadline: <strong>15th July, 2024</strong></li>
                            <li>SIGHAN 2024 Workshop: <strong>August 16, 2024</strong></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- ============================================================================ -->
    
    <div class="sharetask" id="ref">
        
        <div class="part">
            <h1>References</h1>
            <!-- <h2>References</h2> -->
            <div class="list">
                
                <ul>
                    <li>Hongjie Cai, Rui Xia, and Jianfei Yu. 2021. Aspect-Category-Opinion-Sentiment quadruple extraction with implicit aspects and opinions. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 340-350.</li>
                    <li>Shaowei Chen, Yu Wang, Jie Liu and Yuelin Wang. 2021. Bidirectional machine reading comprehension for aspect sentiment triplet extraction. In Proceedings of the 35th AAAI Conference on Artificial Intelligence, pages 12666-12674.</li>
                    <li>Tianhao Gao, Jun Fang, Hanyu Liu, Zhiyuan Liu, Chao Liu, Pengzhang Liu, Yongjun Bao and Weipeng Yan. 2022. LEGO-ABSA: A prompt-based task assemblable unified generative framework for multi-task aspect-based sentiment analysis. In Proceedings of the 29th International Conference on Computational Linguistics, pages 7002-7012.</li>
                    <li>Lung-Hao Lee, Jian-Hong Li and Liang-Chih Yu. 2022. Chinese EmoBank: Building valence-arousal resources for dimensional sentiment analysis. ACM Transactions on Asian and Low-Resource Language Information Processing, 21(4), Article 65, 18 pages. </li>
                    <li>Yue Mao, Yi Shen, Jingchao Yang, Xiaoying Zhu and Longjun Cai. 2022. Seq2Path: Generating sentiment tuples as paths of a tree. In Findings of the Association for Computational Linguistics: ACL 2022, pages 2215-2225.</li>
                    <li>Yue Mao, Yi Shen, Chao Yu and Longjun Cai. 2021. A joint training dual-MRC framework for aspect based sentiment analysis. In Proceedings of the 35th AAAI Conference on Artificial Intelligence, pages 13543-13551. </li>
                    <li>Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, Wei Lu and Luo Si. 2020. Knowing what, how, and why: a near complete solution for aspect-based sentiment analysis. In Proceedings of the 34th AAAI Conference on Artificial Intelligence, pages 8600-8607. </li>
                    <li>Joseph J. Peper and Lu Wang. 2022. Generative aspect-based sentiment analysis with contrastive learning and expressive structure. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 6118-6124.</li>
                    <li>Maria Pontiki, Dimitrios Galanis, Haris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar, Mohammad AL-Smadi, Mahmoud AI-Ayyoub, Yanyan Zhao, Bing Qin, Orphee De Clercq, Veronique Hoste, Marianna Apidianaki, Xavier Tannier, Natalia Loukachevitch. Evgeny Kotelnikov, Nuria Bel, Salud Maria Jimenez-Zafra and Gulsen Eryigit. 2016. SemEval-2016 Task 5: Aspect Based Sentiment Analysis. In Proceedings of the 10th International Workshop on Semantic Evaluation, pages 19-30.</li>
                    <li>Maria Pontiki, Dimitrios Galanis, Haris Papageorgiou, Suresh Manandhar and Ion Androutsopoulos. SemEval-2015 Task 12: Aspect Based Sentiment Analysis. In Proceedings of the 10th International Workshop on Semantic Evaluation, pages 486-495.</li>
                    <li>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Haris Papageorgiou, Ion Androutsopoulos and Suresh Manandhar. 2014. SemEval-2014 Task 4: Aspect Based Sentiment Analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation, pages 27-35.</li>
                    <li>James A Russel. 1980. A circumplex model of affect. Journal of Personality and Social Psychology, 39(6): 1161-1178.</li>
                    <li>Zhen Wu, Chengcan Ying, Fei Zhao, Zhifang Fan, Xinyu Dai, and Rui Xia. 2020. Grid tagging scheme for end-to-end fine-grained opinion extraction. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 2576-2585. </li>
                    <li>Lu Xu, Hao Li, Wei Lu, and Lidong Bing. 2020. Position-aware tagging for aspect sentiment triplet extraction. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 2339-2349. </li>
                    <li>Li Yuan, Jin Wang, Liang-Chih Yu, Xuejie Zhang. 2023. Encoding Syntactic Information into Transformers for Aspect-Based Sentiment Triplet Extraction. IEEE Transactions on Affective Computing. DOI: 10.1109/TAFFC.2023.3291730.</li>
                    <li>Chen Zhang, Qiuchi Li, Dawei Song, and Benyou Wang. 2020. A multi-task learning framework for opinion triplet extraction. In Proceedings of the Association for Computational Linguistics: EMNLP 2020, pages 819-829.</li>
                    <li>Wenxuan Zhang, Xin Li, Yang Deng, Lidong Bing and Wai Lam. 2021. Towards generative aspect-based sentiment analysis. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Short Papers), pages 504-510.  </li>
                    <li>Junxian Zhou, Haiqin Yang, Yuxuan He, Hao Mou. and Junbo Yang. 2023. A unified one-step solution for aspect sentiment quad predication. In Findings of the Association for Computational Linguistics: ACL 2023, pages 12249-12265.</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- ============================================================================ -->
    <div class="footer">
        &copy;SIGHAN 2024 Shared Task || Updated: February 23, 2024
    </div>
    
    <!-- 匯入main javascript -->
    <script src="main.js"></script>

</body>

</html>
